{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba10dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb62503",
   "metadata": {},
   "source": [
    "**Imputation of missing values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770e9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/nikak/Desktop/vubaby/DMT/data_DMT/training_set_VU_DM.csv')\n",
    "test_data = pd.read_csv('/Users/nikak/Desktop/vubaby/DMT/data_DMT/test_set_VU_DM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b95f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training data:\n",
      "\n",
      "Missing values percentage in training data:\n",
      "comp1_rate_percent_diff      98.095353\n",
      "comp6_rate_percent_diff      98.060362\n",
      "comp1_rate                   97.581250\n",
      "comp1_inv                    97.387053\n",
      "comp4_rate_percent_diff      97.356256\n",
      "gross_bookings_usd           97.208949\n",
      "comp7_rate_percent_diff      97.206428\n",
      "comp6_rate                   95.156511\n",
      "visitor_hist_starrating      94.920364\n",
      "visitor_hist_adr_usd         94.897735\n",
      "comp6_inv                    94.736633\n",
      "comp4_rate                   93.800797\n",
      "comp7_rate                   93.640058\n",
      "srch_query_affinity_score    93.598552\n",
      "comp4_inv                    93.069001\n",
      "comp7_inv                    92.811677\n",
      "comp3_rate_percent_diff      90.464625\n",
      "comp2_rate_percent_diff      88.781786\n",
      "comp8_rate_percent_diff      87.602118\n",
      "comp5_rate_percent_diff      83.036706\n",
      "comp3_rate                   69.056462\n",
      "comp3_inv                    66.702814\n",
      "comp8_rate                   61.344900\n",
      "comp8_inv                    59.916016\n",
      "comp2_rate                   59.166392\n",
      "comp2_inv                    57.036710\n",
      "comp5_rate                   55.179155\n",
      "comp5_inv                    52.403089\n",
      "orig_destination_distance    32.425766\n",
      "prop_location_score2         21.990151\n",
      "prop_review_score             0.148517\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing values in the training data\n",
    "missing_counts = train_data.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values in training data:\")\n",
    "#print(missing_counts)\n",
    "\n",
    "missing_percent = (missing_counts / len(train_data)) * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values percentage in training data:\")  \n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef642665",
   "metadata": {},
   "source": [
    "- 'visitor_hist_starrating' --> NULL signifies there is no purchase history of the customer\n",
    "- 'visitor_hist_adr_usd' --> similar as above\n",
    "- 'prop_review_score' --> info not available\n",
    "- 'orig_destination_distance' --> info could not be calculated\n",
    "- 'compN_rate' and 'compN_inv' --> no competitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ade0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    # 1. Visitor history: -1 for no history, plus missing flag\n",
    "    df['visitor_hist_starrating_missing'] = df['visitor_hist_starrating'].isnull().astype(int)\n",
    "    df['visitor_hist_adr_usd_missing'] = df['visitor_hist_adr_usd'].isnull().astype(int)\n",
    "    df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(-1)\n",
    "    df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(-1)\n",
    "\n",
    "    # 2. Property review score: -1 for unavailable + missing flag\n",
    "    df['prop_review_score_missing'] = df['prop_review_score'].isnull().astype(int)\n",
    "    df['prop_review_score'] = df['prop_review_score'].fillna(-1)\n",
    "\n",
    "    # 3. Destination distance: impute with median + missing flag\n",
    "    df['orig_destination_distance_missing'] = df['orig_destination_distance'].isnull().astype(int)\n",
    "    df['orig_destination_distance'] = df['orig_destination_distance'].fillna(df['orig_destination_distance'].median())\n",
    "\n",
    "    # 4. prop_location_score2: median impute + flag\n",
    "    if 'prop_location_score2' in df.columns:\n",
    "        df['prop_location_score2_missing'] = df['prop_location_score2'].isnull().astype(int)\n",
    "        df['prop_location_score2'] = df['prop_location_score2'].fillna(df['prop_location_score2'].median())\n",
    "\n",
    "    # 5. srch_query_affinity_score: fill with -1 + flag\n",
    "    if 'srch_query_affinity_score' in df.columns:\n",
    "        df['srch_query_affinity_score_missing'] = df['srch_query_affinity_score'].isnull().astype(int)\n",
    "        df['srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(-1)\n",
    "\n",
    "    return df\n",
    "train = train_data.copy()\n",
    "test = test_data.copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Handle visitor history fields\n",
    "# ---------------------------\n",
    "# visitor_cols = ['visitor_hist_starrating', 'visitor_hist_adr_usd']\n",
    "# for col in visitor_cols:\n",
    "#     train[f'{col}_missing'] = train[col].isnull().astype(int)\n",
    "#     train[col].fillna(-1, inplace=True)  # -1 means no purchase history\n",
    "\n",
    "# # ---------------------------\n",
    "# # Step 2: Handle property review score\n",
    "# # ---------------------------\n",
    "# train['prop_review_score_missing'] = train['prop_review_score'].isnull().astype(int)\n",
    "# train['prop_review_score'].fillna(-1, inplace=True)  # -1 means info not available\n",
    "\n",
    "# # ---------------------------\n",
    "# # Step 3: Handle orig_destination_distance\n",
    "# # ---------------------------\n",
    "# train['orig_destination_distance_missing'] = train['orig_destination_distance'].isnull().astype(int)\n",
    "# train['orig_destination_distance'].fillna(train['orig_destination_distance'].median(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "#This is not needed anymore so I commented it out\n",
    "\n",
    "# # Step 4: Handle compN_* features (rate, inv, and percent diff)\n",
    "# # ---------------------------\n",
    "# rate_cols = [f'comp{i}_rate' for i in range(1, 9)]\n",
    "# inv_cols = [f'comp{i}_inv' for i in range(1, 9)]\n",
    "# diff_cols = [f'comp{i}_rate_percent_diff' for i in range(1, 9)]\n",
    "\n",
    "# # Fill rate and inv with 0 = \"no competitive info\" (neutral)\n",
    "# train[rate_cols] = train[rate_cols].fillna(0)\n",
    "# train[inv_cols] = train[inv_cols].fillna(0)\n",
    "\n",
    "# # Leave diff as NaN so we can average it properly (ignoring missing)\n",
    "# train[diff_cols] = train[diff_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # ---------------------------\n",
    "# # Step 5: Aggregate compN features into clean new features\n",
    "# # ---------------------------\n",
    "# train['expedia_cheaper_count'] = (train[rate_cols] == 1).sum(axis=1)\n",
    "# train['comp_unavailable_count'] = (train[inv_cols] == 1).sum(axis=1)\n",
    "# train['avg_comp_price_diff'] = train[diff_cols].mean(axis=1)\n",
    "\n",
    "# # Optional: drop original compN_* columns\n",
    "# train.drop(columns=rate_cols + inv_cols + diff_cols, inplace=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Done!\n",
    "# ---------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b660322",
   "metadata": {},
   "source": [
    "**Applying Imputation to Train and Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a052ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved imputed train and test data.\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values\n",
    "train = impute_missing_values(train)\n",
    "test = impute_missing_values(test)\n",
    "\n",
    "# Save to CSV\n",
    "train.to_csv(\"train_imputed_CSV.csv\", index=False)\n",
    "test.to_csv(\"test_imputed_CSV.csv\", index=False)\n",
    "\n",
    "# Save to Pickle\n",
    "train.to_pickle(\"train_imputed.pkl\")\n",
    "test.to_pickle(\"test_imputed.pkl\")\n",
    "\n",
    "print(\"Saved imputed train and test data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7b57e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value handling completed.\n",
      "   visitor_hist_starrating  visitor_hist_starrating_missing  \\\n",
      "0                     -1.0                                1   \n",
      "1                     -1.0                                1   \n",
      "2                     -1.0                                1   \n",
      "3                     -1.0                                1   \n",
      "4                     -1.0                                1   \n",
      "\n",
      "   orig_destination_distance  orig_destination_distance_missing  \n",
      "0                      386.6                                  1  \n",
      "1                      386.6                                  1  \n",
      "2                      386.6                                  1  \n",
      "3                      386.6                                  1  \n",
      "4                      386.6                                  1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value handling completed.\")\n",
    "print(train[['visitor_hist_starrating', 'visitor_hist_starrating_missing',\n",
    "             'orig_destination_distance', 'orig_destination_distance_missing'\n",
    "            #  , 'expedia_cheaper_count', 'avg_comp_price_diff'\n",
    "            ]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf8416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor data processed and combined.\n",
      "   cheaper_count  comp_unavailable_count  avg_comp_price_diff\n",
      "0              0                       0                  NaN\n",
      "1              0                       1                  NaN\n",
      "2              0                       0                  NaN\n",
      "3              0                       1                  5.0\n",
      "4              0                       0                  NaN\n"
     ]
    }
   ],
   "source": [
    "# Also not needed anymore\n",
    "# # ---------------------------\n",
    "\n",
    "\n",
    "# # Step 1: Define competitor column groups\n",
    "# train = train_data.copy()\n",
    "# rate_cols = [f'comp{i}_rate' for i in range(1, 9)]\n",
    "# inv_cols = [f'comp{i}_inv' for i in range(1, 9)]\n",
    "# diff_cols = [f'comp{i}_rate_percent_diff' for i in range(1, 9)]\n",
    "\n",
    "# # Step 2: Fill missing values\n",
    "# # Use np.nan for differences to allow proper mean calculation\n",
    "# train[rate_cols] = train[rate_cols].fillna(0)       # 0 = same price (neutral)\n",
    "# train[inv_cols] = train[inv_cols].fillna(0)         # 0 = available\n",
    "# train[diff_cols] = train[diff_cols].fillna(np.nan)  # np.nan to allow correct average\n",
    "\n",
    "# # Step 3: Create aggregated features\n",
    "# train['cheaper_count'] = (train[rate_cols] == 1).sum(axis=1)\n",
    "# train['comp_unavailable_count'] = (train[inv_cols] == 1).sum(axis=1)\n",
    "# train['avg_comp_price_diff'] = train[diff_cols].mean(axis=1)\n",
    "\n",
    "# # Step 4 (optional): Drop the original compX_* columns\n",
    "# train.drop(columns=rate_cols + inv_cols + diff_cols, inplace=True)\n",
    "\n",
    "# # Done!\n",
    "# print(\"Competitor data processed and combined.\")\n",
    "# print(train[['cheaper_count', 'comp_unavailable_count', 'avg_comp_price_diff']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95bb162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training data:\n",
      "\n",
      "Missing values percentage in training data:\n",
      "comp1_rate_percent_diff    98.095353\n",
      "comp6_rate_percent_diff    98.060362\n",
      "comp1_rate                 97.581250\n",
      "comp1_inv                  97.387053\n",
      "comp4_rate_percent_diff    97.356256\n",
      "gross_bookings_usd         97.208949\n",
      "comp7_rate_percent_diff    97.206428\n",
      "comp6_rate                 95.156511\n",
      "comp6_inv                  94.736633\n",
      "comp4_rate                 93.800797\n",
      "comp7_rate                 93.640058\n",
      "comp4_inv                  93.069001\n",
      "comp7_inv                  92.811677\n",
      "comp3_rate_percent_diff    90.464625\n",
      "comp2_rate_percent_diff    88.781786\n",
      "comp8_rate_percent_diff    87.602118\n",
      "comp5_rate_percent_diff    83.036706\n",
      "comp3_rate                 69.056462\n",
      "comp3_inv                  66.702814\n",
      "comp8_rate                 61.344900\n",
      "comp8_inv                  59.916016\n",
      "comp2_rate                 59.166392\n",
      "comp2_inv                  57.036710\n",
      "comp5_rate                 55.179155\n",
      "comp5_inv                  52.403089\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing values in the training data\n",
    "missing_counts = train.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values in training data:\")\n",
    "#print(missing_counts)\n",
    "\n",
    "missing_percent = (missing_counts / len(train)) * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values percentage in training data:\")  \n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd15bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in test data:\n",
      "\n",
      "Missing values percentage in test data:\n",
      "comp1_rate_percent_diff    98.175748\n",
      "comp6_rate_percent_diff    98.041250\n",
      "comp1_rate                 97.663405\n",
      "comp1_inv                  97.481964\n",
      "comp4_rate_percent_diff    97.315546\n",
      "comp7_rate_percent_diff    97.190606\n",
      "comp6_rate                 95.113510\n",
      "comp6_inv                  94.693299\n",
      "comp4_rate                 93.694102\n",
      "comp7_rate                 93.633447\n",
      "comp4_inv                  92.966422\n",
      "comp7_inv                  92.806214\n",
      "comp3_rate_percent_diff    90.498233\n",
      "comp2_rate_percent_diff    88.836689\n",
      "comp8_rate_percent_diff    87.679886\n",
      "comp5_rate_percent_diff    83.063601\n",
      "comp3_rate                 69.249269\n",
      "comp3_inv                  66.905214\n",
      "comp8_rate                 61.639064\n",
      "comp8_inv                  60.217540\n",
      "comp2_rate                 59.348929\n",
      "comp2_inv                  57.225434\n",
      "comp5_rate                 55.195826\n",
      "comp5_inv                  52.395122\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('test_imputed_CSV.csv')\n",
    "# Missing values in the test data\n",
    "missing_counts = test.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values in test data:\")\n",
    "#print(missing_counts)\n",
    "\n",
    "missing_percent = (missing_counts / len(test)) * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "print(\"\\nMissing values percentage in test data:\")  \n",
    "print(missing_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
